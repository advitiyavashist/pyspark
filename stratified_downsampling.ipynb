{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When dealing with unbalanced data, like in the case of fraud detection, we might have to downsample. Sometimes stratified downsampling may be done so as to ensure that training data has equal distribution of target categories for a particular variable for example gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this case the target variable is fraud_status and we are assuming that there are equal number of frauds associated with different values of a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, HiveContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('fraud').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading data \n",
    "path = #put your file path here\n",
    "df = spark.read.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the unique values of variable which forms the basis of stratified sample\n",
    "cat_pandas = df.select('cat_variable').unique().toPandas()\n",
    "#getting the column which is a series and converting it to a list\n",
    "cat_list = cat_pandas['cat_variable'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separating out fraud and non fraud cases as only non fraud cases need to be downsampled\n",
    "df_fraud = df[df['fraud'] == 1]\n",
    "df_non_fraud = df[df['fraud'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#downsampling non fraud cases by a factor of 5 for each unique value in cat_variable\n",
    "downsampling_factor = 5\n",
    "df_sampled_non_fraud, _ = df_non_fraud[df_non_fraud['cat_variable'] == cat_list[0]].randomSplit([1/downsampling_factor,1 - (1/downsampling_factor)])\n",
    "for i in store_list[1:]:\n",
    "    _df_sampled_non_fraud, _ = df_non_fraud[df_non_fraud['cat_variable'] == i].randomSplit([1/downsampling_factor,1 - (1/downsampling_factor)])\n",
    "    df_sampled_non_fraud = df_sampled_non_fraud.unionAll(_df_sampled_non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merging the downsampled non fraud cases with fraud cases\n",
    "df_new = df_sampled_non_fraud.unionAll(df_fraud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

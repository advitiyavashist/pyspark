{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline For Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SQLContext, SparkConf, SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "from pypspark.ml.feature import VectorAssembler, Vector Indexer, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classfication import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassficationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading data\n",
    "#change this to suit your data\n",
    "df = sqlCtx.read... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if your data has columns that contain strings then \n",
    "#an index value needs to assigned to each unique value \n",
    "#so as to input it to a classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as my data had multiple string columns therefore I developed a list of string indexers\n",
    "string_indexer_list = [StringIndexer(inputCol=i[0], outputCol=i[0] + '_index') for i in df.dtypes if i[1]=='string' \n",
    "                       and i[0] not in [#specify columns not to be included as inputs to models like customer_name]]\n",
    "#when we will fit this to the data then it will create new columns with indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input columns you want in the feature vector\n",
    "#note: include the columns that contain indices instead of original string columns\n",
    "cols = [#example:'gender_index', 'total_after_tax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we will assemble the features into a sparse feature vector as the classfier only takes in this format\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vector indexer adds indices to features with unique values below a certain threshhold, essentially makes them into categorical variables\n",
    "vector_indexer = VectorIndexer(inputCols='features', \n",
    "                               outputCol='indexed_features', \n",
    "                               maxCategories=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding indices to the label column\n",
    "label_indexer = StringIndexer(inputCol='insert the name of the target variable', \n",
    "                              outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classifier object\n",
    "rfc = RandomForestClassfier(featuresCol='indexed_features',\n",
    "                            labelCol='label',\n",
    "                            numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#putting all the objects into the pipeline\n",
    "pipeline = Pipeline[stages= [*string_indexer_list, assembler, \n",
    "                             vector_indexer,label_indexer, rfc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "train, test = df.randomSplit([.8,.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fitting the model\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating accuracy\n",
    "accuracy = MulticlassClassificationEvaluator(labelCol='label', predictioCol='prediction'\n",
    "                                            metricName='accuracy')\n",
    "accuracy.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#confusion metric heatmap\n",
    "_heatmap_matrix = prediction.groupBy('prediction', 'label').count().toPandas()\n",
    "heatmap_matrix = _heatmap_matrix.pivot(index ='label', columns='prediction', values='count')\n",
    "cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "sns.heatmap(heatmap_matrix/heatmap_matrix.sum(), cmap=cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
